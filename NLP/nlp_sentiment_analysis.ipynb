{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "df = pd.read_excel('data/bestbuy_reviews.xlsx')\n",
    "df['REVIEW'] = df['TITLE'] + ' ' + df['CONTENT']\n",
    "df['POST DATE'] = pd.to_datetime(df['POST DATE'])\n",
    "df = df.drop(columns=['TITLE', 'CONTENT'])\n",
    "df.insert(0, 'ID', range(0, 0 + len(df)))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "ax = df['RATING'].value_counts().sort_index()\\\n",
    "    .plot(kind='bar',\n",
    "          title='Count of Reviews by Stars',\n",
    "          figsize=(10, 5))\n",
    "ax.set_xlabel('Review Stars')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lumns = ['TITLE', 'CONTENT'])\n",
    "df.insert(0, 'ID', range(0, 0 + len(df)))\n",
    "df.shape\n",
    "print(df.shape)\n",
    "ax = df['RATING'].value_counts().sort_index() \\\n",
    "    .plot(kind='bar',\n",
    "title = 'Count of Reviews by Stars',\n",
    "figsize = (10, 5))\n",
    "ax.set_xlabel('Review Stars')\n",
    "\n",
    "ps = nltk.PorterStemmer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = ''.join([word for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [word for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.head()\n",
    "LEMMATIZER:\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "\n",
    "def lemmatizing(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "\n",
    "df['lemmatized'] = df['review_clean'].apply(lambda x: lemmatizing(x))\n",
    "\n",
    "df.head(10)\n",
    "df['review_clean'] = df.review_clean.apply(' '.join)\n",
    "df.head()\n",
    "N - Gram\n",
    "from nltk.util import ngrams\n",
    "\n",
    "\n",
    "def extract_ngrams(data, num):\n",
    "    n_grams = ngrams(nltk.word_tokenize(data), num)\n",
    "    return [' '.join(grams) for grams in n_grams]\n",
    "\n",
    "\n",
    "df['ngram2'] = df['review_clean'].apply(lambda x: extract_ngrams(x, 2))\n",
    "# df['ngram3'] = df['review_clean'].apply(lambda x: extract_ngrams(x, 3))\n",
    "# df['ngram4'] = df['review_clean'].apply(lambda x: extract_ngrams(x, 4))\n",
    "\n",
    "df.head()\n",
    "\n",
    "Huggingface\n",
    "Roberta\n",
    "Model\n",
    "Sentiment\n",
    "Analysis\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "model_name = f'cardiffnlp/twitter-roberta-base-sentiment'\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def polarity_scores_roberta(review):\n",
    "    encoded_text = tokenizer(review, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "    encoded_text\n",
    "    # print(encoded_text)\n",
    "    output = model(**encoded_text)\n",
    "    # output\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores\n",
    "    scores_dict = {\n",
    "        'negative': scores[0],\n",
    "        'neutral': scores[1],\n",
    "        'positive': scores[2]\n",
    "    }\n",
    "    return scores_dict\n",
    "\n",
    "\n",
    "res = {}\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "        text = row['REVIEW']\n",
    "        myid = row['ID']\n",
    "        # vader_results = sia.polarity_scores(text)\n",
    "        roberta_result = polarity_scores_roberta(text)\n",
    "        res[myid] = {**roberta_result}\n",
    "    except RuntimeError:\n",
    "        print(f'Broke for id {myid}')\n",
    "\n",
    "results_df = pd.DataFrame(res).T\n",
    "results_df = results_df.reset_index().rename(columns={'index': 'ID'})\n",
    "results_df = results_df.merge(df, how='left')\n",
    "results_df.head()\n",
    "sns.pairplot(data=results_df,\n",
    "             vars=['negative', 'neutral', 'positive'],\n",
    "             hue='RATING',\n",
    "             palette='tab10'\n",
    "             )\n",
    "\n",
    "plt.show\n",
    "[Adding 'positivity' column to sort positive, neutral and negative reviews]\n",
    "\n",
    "SORTING\n",
    "METHOD\n",
    "- positivity == '1'  ->  {Reviews\n",
    "with user ratings 4 and 5} AND {'positive'} sentiment is greater than {'negative' + 'neutral'}\n",
    "- positivity == '0'  ->  {Reviews\n",
    "with user ratings 3} AND {'positive' nor 'negative'} is larger than 0.5 (ambiguous)\n",
    "- positivity == '-1'  ->  {Reviews\n",
    "with user ratings 4 and 5} AND {'negative'} sentiment is greater than {'positive' + 'neutral'}\n",
    "\n",
    "results_df['positivity'] = np.where((results_df['RATING'] >= 4) & (results_df['positive'] > 0.5), 1, 0)\n",
    "results_df['positivity'] = np.where((results_df['RATING'] <= 2) & (results_df['negative'] > 0.5), -1,\n",
    "                                    results_df['positivity'])\n",
    "# results_df['hi']= results_df.loc[(results_df['RATING'] >= 4) & (results_df['positive'] > 0.5)]\n",
    "\n",
    "results_df = results_df.reindex(columns=['ID', 'negative', 'neutral', 'positive', 'RATING', 'positivity', 'POST DATE',\n",
    "                                         'AUTHOR', 'REVIEW', 'review_clean', 'lemmatized', 'ngram2'])\n",
    "results_df.head()\n",
    "\n",
    "results_df['lemmatized_s'] = [', '.join(map(str, l)) for l in results_df['lemmatized']]\n",
    "results_df['ngram2_s'] = [', '.join(map(str, l)) for l in results_df['ngram2']]\n",
    "# results_df['ngram3_s'] = [', '.join(map(str, l)) for l in results_df['ngram3']]\n",
    "# results_df['ngram4_s'] = [', '.join(map(str, l)) for l in results_df['ngram4']]\n",
    "\n",
    "\n",
    "# a = pd.Series([item for sublist in results_df.lemmatized_s for item in sublist])\n",
    "# a\n",
    "d = results_df.groupby(results_df['positivity']).agg({'lemmatized_s': lambda x: ', '.join(x),\n",
    "                                                      'ngram2_s': lambda x: ', '.join(x)})\n",
    "# 'ngram3_s': lambda x: ', '.join(x),\n",
    "# 'ngram4_s': lambda x: ', '.join(x)})\n",
    "\n",
    "lem_pos = d['lemmatized_s'][1]\n",
    "lem_neu = d['lemmatized_s'][0]\n",
    "lem_neg = d['lemmatized_s'][-1]\n",
    "\n",
    "tags_pos = lem_pos.split(', ')  # Positivity [1]\n",
    "tags_neu = lem_neu.split(', ')  # Positivity [0]\n",
    "tags_neg = lem_neg.split(', ')  # Positivity [-1]\n",
    "res_pos = {}\n",
    "res_neu = {}\n",
    "res_neg = {}\n",
    "\n",
    "\n",
    "def word_count(tags, res):\n",
    "    for i in tags:\n",
    "        res[i] = tags.count(i)\n",
    "    return res\n",
    "\n",
    "\n",
    "res_pos = word_count(tags_pos, res_pos)\n",
    "res_neu = word_count(tags_neu, res_neu)\n",
    "res_neg = word_count(tags_neg, res_neg)\n",
    "\n",
    "lemmatized_count = pd.DataFrame([res_pos, res_neu, res_neg]).astype('Int64').T.fillna(0)\n",
    "lemmatized_count.columns = ['POS(1)', 'NEU(0)', 'NEG(-1)']\n",
    "lemmatized_count = lemmatized_count.sort_values(by='POS(1)', ascending=False)\n",
    "lemmatized_count.name = 'Word Count by Sentiment'\n",
    "lemmatized_count  # sorted by Most Frequent in 'positive'\n",
    "\n",
    "# res_sort = {k: v for k, v in sorted(lemmatized_count['1'].items(), key=lambda item: item[1], reverse=True)[:30]}\n",
    "# res_sort\n",
    "\n",
    "ngram2_pos = d['ngram2_s'][1]\n",
    "ngram2_neu = d['ngram2_s'][0]\n",
    "ngram2_neg = d['ngram2_s'][-1]\n",
    "\n",
    "tags_bi_pos = ngram2_pos.split(', ')  # Positive Bi-gram\n",
    "tags_bi_neu = ngram2_neu.split(', ')  # Neutral Bi-gram\n",
    "tags_bi_neg = ngram2_neg.split(', ')  # Negative Bi-gram\n",
    "\n",
    "res_bi_pos = {}\n",
    "res_bi_neu = {}\n",
    "res_bi_neg = {}\n",
    "\n",
    "\n",
    "def word_count(tags, res):\n",
    "    for i in tags:\n",
    "        res[i] = tags.count(i)\n",
    "    return res\n",
    "\n",
    "\n",
    "res_bi_pos = word_count(tags_bi_pos, res_bi_pos)\n",
    "res_bi_neu = word_count(tags_bi_neu, res_bi_neu)\n",
    "res_bi_neg = word_count(tags_bi_neg, res_bi_neg)\n",
    "\n",
    "bigram_count = pd.DataFrame([res_bi_pos, res_bi_neu, res_bi_neg]).astype('Int64').T.fillna(0)\n",
    "bigram_count.columns = ['POS(1)', 'NEU(0)', 'NEG(-1)']\n",
    "bigram_count = bigram_count.sort_values(by='POS(1)', ascending=False)\n",
    "bigram_count.name = 'Bigram (2 adjacent words) Count by Sentiment'\n",
    "bigram_count  # Sorted by Most Frequent in 'positive'\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# word = lem_pos\n",
    "stopwords_c = ['vacuum', 'x000d']\n",
    "wordcloud_pos = WordCloud(stopwords=stopwords_c, width=1000, height=500).generate(lem_pos)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.imshow(wordcloud_pos)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "# plt.savefig(\"your_file_name\"+\".png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# plt.close()\n",
    "wordcloud_neg = WordCloud(stopwords=stopwords_c, width=1000, height=500, colormap='RdPu').generate(lem_neg)\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.imshow(wordcloud_neg)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "wordcloud_bi_neg = WordCloud(stopwords=stopwords_c, width=1000, height=500).generate_from_frequencies(res_bi_pos)\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.imshow(wordcloud_bi_neg)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
